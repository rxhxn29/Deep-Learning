#  Simple Neural Network from Scratch (Python + NumPy)

This repository contains a minimal implementation of a **single-layer neural network** (logistic regression style) built using **NumPy only**.  
It supports **Batch Gradient Descent**, **Stochastic Gradient Descent**, and **Momentum Gradient Descent** with clean and easy-to-read code.

---

##  Features
- Implements three optimization algorithms:
  - **Batch Gradient Descent**
  - **Stochastic Gradient Descent (SGD)**
  - **Momentum Gradient Descent**
- Includes common activation functions:
  - Sigmoid  
  - Tanh  
  - ReLU  
  - Leaky ReLU  
  - Step Function  
- Works entirely without ML libraries like TensorFlow or PyTorch.
- Great for learning and teaching the fundamentals of neural networks and gradient descent.

